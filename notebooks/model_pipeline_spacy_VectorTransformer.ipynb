{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pipelines\n",
    "As the evaluation function takes scikit-learn compatible estimators, it is possible to use scikits <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">pipelines</a> to create models in an easy to use and concise way. A pipeline chains feature transformers with an estimator at the end. In the following, we will evalaute a support vector machine with linear kernel chaining a custom column-selector, a `CountVectorizer` and a `MaxAbsScaler` transformer as preprocessing steps in form of such a pipeline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading training data from ../data/external/kaggle/train.csv...\n",
      "INFO:root:-> Number of samples: 7613\n",
      "INFO:root:-> Number of features: 3\n",
      "INFO:root:Evaluating model with 1 experiment(s) of 10-fold Cross Validation...\n",
      "INFO:root:Run 1/10 finished\n",
      "INFO:root:Run 2/10 finished\n",
      "INFO:root:Run 3/10 finished\n",
      "INFO:root:Run 4/10 finished\n",
      "INFO:root:Run 5/10 finished\n",
      "INFO:root:Run 6/10 finished\n",
      "INFO:root:Run 7/10 finished\n",
      "INFO:root:Run 8/10 finished\n",
      "INFO:root:Run 9/10 finished\n",
      "INFO:root:Run 10/10 finished\n",
      "INFO:root:---\n",
      "INFO:root:Expected submission results (F1-Score): around 0.77\n",
      "INFO:root:F1-Score: 0.78 (training); 0.77 (test)\n",
      "INFO:root:Accuracy: 81.38% (training); 80.01% (test)\n",
      "INFO:root:Recall: 77.31% (training); 75.85% (test)\n",
      "INFO:root:Precision: 78.92% (training); 77.22% (test)\n",
      "INFO:root:---\n",
      "INFO:root:Retraining model on the complete data set...\n",
      "INFO:root:-> F1-Score on complete training set: 0.78\n",
      "INFO:root:-> Stored model to ../models/model_2021-01-12_181935_Pipeline_1x10cv_0.77.pck\n",
      "INFO:root:-> Stored submission file to ../models/submission_2021-01-12_181935_Pipeline_1x10cv_0.77.csv\n",
      "INFO:root:Evaluation finished.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing, feature_extraction, linear_model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "import evaluation\n",
    "\n",
    "from sklearn import base\n",
    "\n",
    "\n",
    "class WordVectorTransformer(base.TransformerMixin, base.BaseEstimator):\n",
    "    def __init__(self, model=\"en_core_web_lg\"):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        nlp = spacy.load(self.model)\n",
    "        return np.concatenate([nlp(doc).vector.reshape(1,-1) for doc in X])    \n",
    "    \n",
    "# Setup model as transformer pipeline with logistic regression\n",
    "model = Pipeline([\n",
    "    # Extract the `text` feature\n",
    "    ('col-selector', preprocessing.FunctionTransformer(func=lambda X: X[:, 2])),\n",
    "    #WordVectorTransformer of Spacy\n",
    "    ('WordVectorTransformer', WordVectorTransformer()),\n",
    "    # Scale data to maximum absolute value of 1 and keep sparsity properties\n",
    "    ('scaler', preprocessing.MaxAbsScaler()),\n",
    "    # Classify data with a linear SVM\n",
    "    ('clf', svm.LinearSVC(C=1e-2, class_weight='balanced', random_state=42)) #linear_model.RidgeClassifier)\n",
    "])\n",
    "\n",
    "# Evaluate model pipeline\n",
    "evaluation.evaluate(model, store_model=True, store_submission=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual submission result is `...`.\n",
    "\n",
    "mit Model \"en_cor_web_sm\" ca. 64%\n",
    "\n",
    "Model \"en_core_web_lg\" -  WordVectorTransformer() +  'scaler', preprocessing.MaxAbsScaler() & 'clf', svm.LinearSVC\n",
    "INFO:root:Expected submission results (F1-Score): around 0.77\n",
    "INFO:root:F1-Score: 0.78 (training); 0.77 (test)\n",
    "INFO:root:Accuracy: 81.38% (training); 80.01% (test)\n",
    "INFO:root:Recall: 77.31% (training); 75.85% (test)\n",
    "INFO:root:Precision: 78.92% (training); 77.22% (test)\n",
    "\n",
    "INFO:root:-> F1-Score on complete training set: 0.78\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
