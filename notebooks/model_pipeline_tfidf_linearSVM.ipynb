{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pipelines\n",
    "As the evaluation function takes scikit-learn compatible estimators, it is possible to use scikits <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">pipelines</a> to create models in an easy to use and concise way. A pipeline chains feature transformers with an estimator at the end. In the following, we evaluate a support vector machine with linear kernel chaining a custom column-selector, a `CountVectorizer` and a `MaxAbsScaler` transformer as preprocessing steps in the form of such a pipeline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading training data from ../data/external/kaggle/train.csv...\n",
      "INFO:root:-> Number of samples: 7613\n",
      "INFO:root:-> Number of features: 3\n",
      "INFO:root:Evaluating model with 1 experiment(s) of 10-fold Cross Validation...\n",
      "INFO:root:Run 1/10 finished\n",
      "INFO:root:Run 2/10 finished\n",
      "INFO:root:Run 3/10 finished\n",
      "INFO:root:Run 4/10 finished\n",
      "INFO:root:Run 5/10 finished\n",
      "INFO:root:Run 6/10 finished\n",
      "INFO:root:Run 7/10 finished\n",
      "INFO:root:Run 8/10 finished\n",
      "INFO:root:Run 9/10 finished\n",
      "INFO:root:Run 10/10 finished\n",
      "INFO:root:---\n",
      "INFO:root:Expected submission results (F1-Score): around 0.71\n",
      "INFO:root:F1-Score: 0.75 (training); 0.71 (test)\n",
      "INFO:root:Accuracy: 78.44% (training); 74.45% (test)\n",
      "INFO:root:Recall: 75.38% (training); 73.43% (test)\n",
      "INFO:root:Precision: 74.68% (training); 69.06% (test)\n",
      "INFO:root:Evaluation finished.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing, base, svm, linear_model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import evaluation\n",
    "\n",
    "# Setup model as transformer pipeline with logistic regression\n",
    "model = Pipeline([\n",
    "    # Extract the `text` feature\n",
    "    ('col-selector', preprocessing.FunctionTransformer(func=lambda X: X[:, 2])),\n",
    "    #TF-IDF Vectorizer\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    # Classify data with a linear SVM\n",
    "    ('clf', svm.LinearSVC(C=1e-2, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Evaluate model pipeline\n",
    "evaluation.evaluate(model, store_model=False, store_submission=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C=1e-2:\n",
    "INFO:root:Expected submission results (F1-Score): around 0.71\n",
    "INFO:root:F1-Score: 0.75 (training); 0.71 (test)\n",
    "INFO:root:Accuracy: 78.44% (training); 74.45% (test)\n",
    "INFO:root:Recall: 75.38% (training); 73.43% (test)\n",
    "INFO:root:Precision: 74.68% (training); 69.06% (test)\n",
    "INFO:root:Evaluation finished.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading training data from ../data/external/kaggle/train.csv...\n",
      "INFO:root:-> Number of samples: 7613\n",
      "INFO:root:-> Number of features: 3\n",
      "INFO:root:Evaluating model with 1 experiment(s) of 10-fold Cross Validation...\n",
      "INFO:root:Run 1/10 finished\n",
      "INFO:root:Run 2/10 finished\n",
      "INFO:root:Run 3/10 finished\n",
      "INFO:root:Run 4/10 finished\n",
      "INFO:root:Run 5/10 finished\n",
      "INFO:root:Run 6/10 finished\n",
      "INFO:root:Run 7/10 finished\n",
      "INFO:root:Run 8/10 finished\n",
      "INFO:root:Run 9/10 finished\n",
      "INFO:root:Run 10/10 finished\n",
      "INFO:root:---\n",
      "INFO:root:Expected submission results (F1-Score): around 0.76\n",
      "INFO:root:F1-Score: 0.96 (training); 0.76 (test)\n",
      "INFO:root:Accuracy: 96.91% (training); 79.06% (test)\n",
      "INFO:root:Recall: 95.69% (training); 75.11% (test)\n",
      "INFO:root:Precision: 97.09% (training); 75.90% (test)\n",
      "INFO:root:Evaluation finished.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing, base, svm, linear_model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import evaluation\n",
    "\n",
    "# Setup model as transformer pipeline with logistic regression\n",
    "model = Pipeline([\n",
    "    # Extract the `text` feature\n",
    "    ('col-selector', preprocessing.FunctionTransformer(func=lambda X: X[:, 2])),\n",
    "    #TF-IDF Vectorizer\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    # Classify data with a linear SVM\n",
    "    ('clf', svm.LinearSVC(C=0.5, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Evaluate model pipeline\n",
    "evaluation.evaluate(model, store_model=False, store_submission=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=0.5:\n",
    "INFO:root:Expected submission results (F1-Score): around 0.76\n",
    "INFO:root:F1-Score: 0.96 (training); 0.76 (test)\n",
    "INFO:root:Accuracy: 96.91% (training); 79.06% (test)\n",
    "INFO:root:Recall: 95.69% (training); 75.11% (test)\n",
    "INFO:root:Precision: 97.09% (training); 75.90% (test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
