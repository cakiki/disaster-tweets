{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pipelines\n",
    "As the evaluation function takes scikit-learn compatible estimators, it is possible to use scikits <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">pipelines</a> to create models in an easy to use and concise way. A pipeline chains feature transformers with an estimator at the end. In the following, we evaluate the results with an TfidfVectorizer. For the Classification it uses the Naive Bayes and\n",
    "linear SVC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer with MultinomialNB\n",
    "Using TfidfVectorizer, a combination of CountVectorizer and TfidfTransformer.\n",
    "For the Classification we use the MultinomialNB, a Naive Bayes Classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing, base\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import evaluation\n",
    "\n",
    "# Setup model as transformer pipeline with logistic regression\n",
    "model = Pipeline([\n",
    "    # Extract the `text` feature\n",
    "    ('col-selector', preprocessing.FunctionTransformer(func=lambda X: X[:, 2])),\n",
    "    #TF-IDF Vectorizer\n",
    "    ('tfidf', TfidfVectorizer(analyzer ='word', stop_words = 'english')),\n",
    "    #NaiveBayes-Classifier\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Evaluate model pipeline\n",
    "evaluation.evaluate(model, store_model=False, store_submission=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFO:root:Expected submission results (F1-Score): around 0.73\n",
    "INFO:root:F1-Score: 0.85 (training); 0.73 (test)\n",
    "INFO:root:Accuracy: 88.78% (training); 79.77% (test)\n",
    "INFO:root:Recall: 76.96% (training); 62.18% (test)\n",
    "INFO:root:Precision: 96.17% (training); 87.03% (test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##tfidfVectorizer with Naive Bayes Classification and GridSearchCV for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading training data from ../data/external/kaggle/train.csv...\n",
      "INFO:root:-> Number of samples: 7613\n",
      "INFO:root:-> Number of features: 3\n",
      "INFO:root:Evaluating model with 1 experiment(s) of 10-fold Cross Validation...\n",
      "INFO:root:Run 1/10 finished\n",
      "INFO:root:Run 2/10 finished\n",
      "INFO:root:Run 3/10 finished\n",
      "INFO:root:Run 4/10 finished\n",
      "INFO:root:Run 5/10 finished\n",
      "INFO:root:Run 6/10 finished\n",
      "INFO:root:Run 7/10 finished\n",
      "INFO:root:Run 8/10 finished\n",
      "INFO:root:Run 9/10 finished\n",
      "INFO:root:Run 10/10 finished\n",
      "INFO:root:---\n",
      "INFO:root:Expected submission results (F1-Score): around 0.73\n",
      "INFO:root:F1-Score: 0.97 (training); 0.73 (test)\n",
      "INFO:root:Accuracy: 97.62% (training); 78.43% (test)\n",
      "INFO:root:Recall: 95.69% (training); 68.82% (test)\n",
      "INFO:root:Precision: 98.72% (training); 78.35% (test)\n",
      "INFO:root:Evaluation finished.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing, base\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import evaluation\n",
    "  \n",
    "# Setup parameters for gridsearch\n",
    "hyper_param = {'alpha': (1e-2, 1e-3),\n",
    "}    \n",
    "\n",
    "    \n",
    "# Setup model as transformer pipeline with logistic regression\n",
    "model = Pipeline([\n",
    "    # Extract the `text` feature\n",
    "    ('col-selector', preprocessing.FunctionTransformer(func=lambda X: X[:, 2])),\n",
    "    #('vect',  feature_extraction.text.CountVectorizer()),\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    #NaiveBayes-Classifier\n",
    "    ('clf', GridSearchCV(MultinomialNB(), hyper_param, scoring='f1')),\n",
    "])\n",
    "\n",
    "# Evaluate model pipeline\n",
    "evaluation.evaluate(model, store_model=False, store_submission=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFO:root:Expected submission results (F1-Score): around 0.73\n",
    "INFO:root:F1-Score: 0.97 (training); 0.73 (test)\n",
    "INFO:root:Accuracy: 97.62% (training); 78.43% (test)\n",
    "INFO:root:Recall: 95.69% (training); 68.82% (test)\n",
    "INFO:root:Precision: 98.72% (training); 78.35% (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TfidfVectorizer with linear SVM Classifier\n",
    "Using again the TfidfVectorizer, but now a linear SVM Classifier for the Classification.\n",
    "Vatriable C for the SVM Classifier is set to 1e-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading training data from ../data/external/kaggle/train.csv...\n",
      "INFO:root:-> Number of samples: 7613\n",
      "INFO:root:-> Number of features: 3\n",
      "INFO:root:Evaluating model with 1 experiment(s) of 10-fold Cross Validation...\n",
      "INFO:root:Run 1/10 finished\n",
      "INFO:root:Run 2/10 finished\n",
      "INFO:root:Run 3/10 finished\n",
      "INFO:root:Run 4/10 finished\n",
      "INFO:root:Run 5/10 finished\n",
      "INFO:root:Run 6/10 finished\n",
      "INFO:root:Run 7/10 finished\n",
      "INFO:root:Run 8/10 finished\n",
      "INFO:root:Run 9/10 finished\n",
      "INFO:root:Run 10/10 finished\n",
      "INFO:root:---\n",
      "INFO:root:Expected submission results (F1-Score): around 0.71\n",
      "INFO:root:F1-Score: 0.75 (training); 0.71 (test)\n",
      "INFO:root:Accuracy: 78.44% (training); 74.45% (test)\n",
      "INFO:root:Recall: 75.38% (training); 73.43% (test)\n",
      "INFO:root:Precision: 74.68% (training); 69.06% (test)\n",
      "INFO:root:Evaluation finished.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing, base, svm, linear_model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import evaluation\n",
    "\n",
    "# Setup model as transformer pipeline with logistic regression\n",
    "model = Pipeline([\n",
    "    # Extract the `text` feature\n",
    "    ('col-selector', preprocessing.FunctionTransformer(func=lambda X: X[:, 2])),\n",
    "    #TF-IDF Vectorizer\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    # Classify data with a linear SVM\n",
    "    ('clf', svm.LinearSVC(C=1e-2, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Evaluate model pipeline\n",
    "evaluation.evaluate(model, store_model=False, store_submission=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C=1e-2:\n",
    "INFO:root:Expected submission results (F1-Score): around 0.71\n",
    "INFO:root:F1-Score: 0.75 (training); 0.71 (test)\n",
    "INFO:root:Accuracy: 78.44% (training); 74.45% (test)\n",
    "INFO:root:Recall: 75.38% (training); 73.43% (test)\n",
    "INFO:root:Precision: 74.68% (training); 69.06% (test)\n",
    "INFO:root:Evaluation finished.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TfidfVectorizer with linear SVM Classifier\n",
    "Using again the TfidfVectorizer, but now a linear SVM Classifier for the Classification.\n",
    "Vatriable C for the SVM Classifier is set to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading training data from ../data/external/kaggle/train.csv...\n",
      "INFO:root:-> Number of samples: 7613\n",
      "INFO:root:-> Number of features: 3\n",
      "INFO:root:Evaluating model with 1 experiment(s) of 10-fold Cross Validation...\n",
      "INFO:root:Run 1/10 finished\n",
      "INFO:root:Run 2/10 finished\n",
      "INFO:root:Run 3/10 finished\n",
      "INFO:root:Run 4/10 finished\n",
      "INFO:root:Run 5/10 finished\n",
      "INFO:root:Run 6/10 finished\n",
      "INFO:root:Run 7/10 finished\n",
      "INFO:root:Run 8/10 finished\n",
      "INFO:root:Run 9/10 finished\n",
      "INFO:root:Run 10/10 finished\n",
      "INFO:root:---\n",
      "INFO:root:Expected submission results (F1-Score): around 0.76\n",
      "INFO:root:F1-Score: 0.96 (training); 0.76 (test)\n",
      "INFO:root:Accuracy: 96.91% (training); 79.06% (test)\n",
      "INFO:root:Recall: 95.69% (training); 75.11% (test)\n",
      "INFO:root:Precision: 97.09% (training); 75.90% (test)\n",
      "INFO:root:Evaluation finished.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing, base, svm, linear_model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import evaluation\n",
    "\n",
    "# Setup model as transformer pipeline with logistic regression\n",
    "model = Pipeline([\n",
    "    # Extract the `text` feature\n",
    "    ('col-selector', preprocessing.FunctionTransformer(func=lambda X: X[:, 2])),\n",
    "    #TF-IDF Vectorizer\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    # Classify data with a linear SVM\n",
    "    ('clf', svm.LinearSVC(C=0.5, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Evaluate model pipeline\n",
    "evaluation.evaluate(model, store_model=False, store_submission=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=0.5:\n",
    "INFO:root:Expected submission results (F1-Score): around 0.76\n",
    "INFO:root:F1-Score: 0.96 (training); 0.76 (test)\n",
    "INFO:root:Accuracy: 96.91% (training); 79.06% (test)\n",
    "INFO:root:Recall: 95.69% (training); 75.11% (test)\n",
    "INFO:root:Precision: 97.09% (training); 75.90% (test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TfidfVectorizer with linear SVM Classifier and GridSearchCV.\n",
    "Using again the TfidfVectorizer, but now a linear SVM Classifier for the Classification.\n",
    "to optimize the Classifier GridSearchCv is used additionaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing, base, svm, linear_model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import evaluation\n",
    "\n",
    "hyper_param = [{\n",
    "    'kernel': ['rbf'],\n",
    "    'C': [1, 10, 100],\n",
    "    'gamma': ['scale']\n",
    "}]\n",
    "\n",
    "# Setup model as transformer pipeline with logistic regression\n",
    "model = Pipeline([\n",
    "    # Extract the `text` feature\n",
    "    ('col-selector', preprocessing.FunctionTransformer(func=lambda X: X[:, 2])),\n",
    "    #TF-IDF Vectorizer\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    # Classify data with a linear SVM\n",
    "     ('clf', GridSearchCV(svm.SVC(), hyper_param, scoring='f1'))\n",
    "])\n",
    "#('clf', svm.LinearSVC(C=1e-2, class_weight='balanced', random_state=42))])\n",
    "\n",
    "# Evaluate model pipeline\n",
    "evaluation.evaluate(model, store_model=False, store_submission=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFO:root:Expected submission results (F1-Score): around 0.76\n",
    "INFO:root:F1-Score: 1.00 (training); 0.76 (test)\n",
    "INFO:root:Accuracy: 99.67% (training); 80.47% (test)\n",
    "INFO:root:Recall: 99.49% (training); 71.94% (test)\n",
    "INFO:root:Precision: 99.73% (training); 80.53% (test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
