{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pipelines\n",
    "As the evaluation function takes scikit-learn compatible estimators, it is possible to use scikits <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">pipelines</a> to create models in an easy to use and concise way. A pipeline chains feature transformers with an estimator at the end. In the following, we evaluate a support vector machine with linear kernel chaining a custom column-selector, a `CountVectorizer` and a `MaxAbsScaler` transformer as preprocessing steps in the form of such a pipeline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading training data from ../data/external/kaggle/train.csv...\n",
      "INFO:root:-> Number of samples: 7613\n",
      "INFO:root:-> Number of features: 3\n",
      "INFO:root:Evaluating model with 1 experiment(s) of 10-fold Cross Validation...\n",
      "INFO:root:Run 1/10 finished\n",
      "INFO:root:Run 2/10 finished\n",
      "INFO:root:Run 3/10 finished\n",
      "INFO:root:Run 4/10 finished\n",
      "INFO:root:Run 5/10 finished\n",
      "INFO:root:Run 6/10 finished\n",
      "INFO:root:Run 7/10 finished\n",
      "INFO:root:Run 8/10 finished\n",
      "INFO:root:Run 9/10 finished\n",
      "INFO:root:Run 10/10 finished\n",
      "INFO:root:---\n",
      "INFO:root:Expected submission results (F1-Score): around 0.73\n",
      "INFO:root:F1-Score: 0.85 (training); 0.73 (test)\n",
      "INFO:root:Accuracy: 88.78% (training); 79.77% (test)\n",
      "INFO:root:Recall: 76.96% (training); 62.18% (test)\n",
      "INFO:root:Precision: 96.17% (training); 87.03% (test)\n",
      "INFO:root:Evaluation finished.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing, base\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import evaluation\n",
    "\n",
    "# Setup model as transformer pipeline with logistic regression\n",
    "model = Pipeline([\n",
    "    # Extract the `text` feature\n",
    "    ('col-selector', preprocessing.FunctionTransformer(func=lambda X: X[:, 2])),\n",
    "    #TF-IDF Vectorizer\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    #NaiveBayes-Classifier\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Evaluate model pipeline\n",
    "evaluation.evaluate(model, store_model=False, store_submission=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFO:root:Expected submission results (F1-Score): around 0.73\n",
    "INFO:root:F1-Score: 0.85 (training); 0.73 (test)\n",
    "INFO:root:Accuracy: 88.78% (training); 79.77% (test)\n",
    "INFO:root:Recall: 76.96% (training); 62.18% (test)\n",
    "INFO:root:Precision: 96.17% (training); 87.03% (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
